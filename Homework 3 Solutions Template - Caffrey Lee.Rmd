---
title: "Homework 3"
author: "Caffrey Lee (cl3802, cl3802@columbia.edu)"
date: ""
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, eval = TRUE, comment="", warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=55), tidy = TRUE)
```



```{r read_data_intro, echo=FALSE}
library(data.table)
library(DT)
setwd("~/Applied Data Science/hw3/data")
dat <- fread(input = "../Data/Homework 3 Data.csv", verbose = FALSE)
num.lines <- 20
question.counter = 0
```

```{r constants}
id.name <- "id"
age.name <- "Age"
gender.name <- "Gender"
income.name <- "Income"
region.name <- "Region"
persona.name <- "Persona"

product.name <- "Product"
awareness.name <- "Awareness"
consideration.name <- "Consideration"
consumption.name <- "Consumption"
satisfaction.name <- "Satisfaction"
advocacy.name <- "Advocacy"

pattern.bp <- "BP_"

age.group.name <- "Age Group"
income.group.name <- "Income Group"
```
## Building a Reporting Engine

All of the previous homework assignments have asked you to perform analyses while writing a report.  This time, you will build a dynamic reporting system that can display a wider range of information.  Each of the questions below will include an analytical component.  Then you will build a section of a reporting engine that can answer a whole class of similar questions.

The analytical questions may be written up in the usual style of a report.  We will also ask you to turn in your reporting engine as an RMarkdown file.

## About The Data

We will be working with a simulated data set related to market research surveys for mobile phone products.

**Main File**:  Homework 3 Data.csv

**Delimiter**:  Each column of each file is separated with a comma **,** delimiter.

**Header** The first row of the data set includes the column names, and each subsequent row includes one observation of values.  Here is a selection of `r num.lines` randomly sampled lines from the data set:

```{r show_header, echo=FALSE, eval = TRUE}
library(DT)
sampled.rows <- sample(x = 1:dat[, .N], size = num.lines, replace = FALSE)
datatable(data = dat[sampled.rows,], rownames = FALSE)
```

Your organization's market research team created a survey to collect information about the customer base.  A large, representative sample of customers was surveyed.  Each row of the data set records the information for a single respondent's reactions about a single product.  The data are organized in long, melted format.  Each person in multiple rows, with one for each product.  The Main File includes the following variables:

- **id**:  This is a unique identifier for the respondent.  The data are structured in a **melted** format.  Each person's responses show up in multiple rows, with 1 row for each product.

- **Age**:  This is the subject's age in years (rounded down) at the time of survey.  For the purpose of this study, all of the respondents should be at least 18 years old.  A number of questions will ask you to categorize the respondents into the following groups based on their age:

- **Age Groups**: 
    + At least 18 and under 35.  (Don't include anyone who is 35.)
    + At least 35 and under 50.
    + At least 50 and under 65.
    + At least 65.

- **Gender**:  This identifies the respondent's gender as Male or Female.

- **Income**:  This is the respondent's household income -- the combined income of all members of the household -- rounded to the nearest thousand dollars.  A number of questions will ask you to categorize the respondents into the following groups based on their income:

- **Income Group**:
    + Under $50,000.
    + At least $50,000 and under $75,000.
    + At least $75,000 and under $100,000.
    + At least $100,000 and under $150,000.
    + At least $150,000.

- **Region**:  This is the geographial region within the U.S.A. in which the respondent lives.

- **Persona**:  This is the respondent's marketing profile category.  These were created previously by the marketing organization as a method of dividing the respondents into a number of illustrative groups.

- **Product**:  This is the name of each brand of mobile phone that was surveyed.

- **Brand Perceptions**:  There are a number of variables about the respondent's perceptions of the brands.  Each of these variables is labeled with the form **BP_quality_min_max**.  The word or phrase used in place of the quality is the perception that was surveyed.  The respondents were asked to rate that perception on an integer scale from the minimum to the maximum listed values.

- **Outcomes**:  These are the marketing states of engagement that the survey was designed to investigate.  The outcomes include Awareness, Consideration, Consumption, Satisfaction, and Advocacy.  Satisfaction was assessed on an integer scale from 0 to 10.  All of the other outcomes are binary variables.  For the purposes of this assignment, it would be reasonable to place all of the outcomes on a percentage scale from 0 to 100.

**Note**:  A dynamic progression of the questions in the survey was utilized.  Those not aware of a product were not asked about any further states of engagement.  Those who were aware were asked about their perception of the brand and also their consideration.  Those who had considered the product were asked about their consumption.  Those who had consumed the product were asked about both their satisfaction and advocaccy.  Any questions that were not asked should result in missing (NA) values for the record.

**Note**:  The description above tells you *the intended structure* of the data set.  However, it's possible that there could be problems lurking in the records.  In the course of doing this assignment, you may uncover some issues.  For instance, you may find an erroneous value.  In this circumstance, it will be necessary to resolve the situation.  Here are some guidelines for doing so:

- If the issue has an obvious solution, then you may recode the data.  For instance, if you see a value of **"True"** for a binary variable, then you may safely assume that this value should have been coded as a 1.
- If the issue does not have an obvious solution, then you can replace the erroneous value with **NA** to denote a missing value.  

In either circumstance, note the problem in your solution and briefly describe the work you did to clean the data.

Then, use the data to answer the following questions and to build a reporting engine according to the specifications described.

```{r question1, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`: Respondent Variables

**a.** In percentage terms, how were the survey's respondents divided into categories for the following variables?  Answer separately for each variable.  Round all percentages to 1 decimal place (e.g. 84.2%).

**Hint**:  Keep in mind that each respondent may appear multiple times in the data set.

```{r functions}
percentage.mark <- function(x, digits = 1)
{
  percentage <- 100*x/dat[, .N]
  rounded.percentage <- round(x = percentage, digits = digits)
  return(sprintf("%.1f %%", rounded.percentage))
}

percentage.mark2 <- function(x, digits = 1)
{
  percentage <- 100*x/dat[, length(unique(get(id.name)))]
  rounded.percentage <- round(x = percentage, digits = digits)
  return(sprintf("%.1f %%", rounded.percentage))
}

round.numerics <- function(x, digits){
  if(is.numeric(x)){
    x <- round(x = x, digits = digits)
  }
  return(x)
}

mean.diff <- function(x, y){
  return(mean(x, na.rm=TRUE) - mean(y, na.rm=TRUE))
}

```
- **Age Group**

```{r age_group}
library(Hmisc)
id.name = "id"
age.name = "Age"
age.group.name = "Age Group"

# Every Id has exact 20 transaction records.
dat[, which(.N != 20), by = id] # 0 

# Demarcating age
cuts.age <- c(18, 35, 50, 65, 120)
dat[, eval(age.group.name) := cut2(x = get(age.name), cuts = cuts.age)]

# Extract age group from the dat
age.tab = dat[, .N, keyby = age.group.name]
unique.age.groups <- dat[, unique(get(age.group.name))]

# Adding a column, called Percentage, to the table
age.tab[, Percentage := age.tab[, lapply(.SD, FUN = 'percentage.mark'), .SDcols = "N"]]

datatable(age.tab)

# Age with uniq
age.uniq.tab = dat[, length((unique(get(id.name)))), keyby = age.group.name]
setnames(x = age.uniq.tab, old = "V1", new = "Numbers")
age.uniq.tab[, Percentage := age.uniq.tab[, lapply(.SD, FUN = 'percentage.mark2'), .SDcols = "Numbers"]]

datatable(age.uniq.tab)
```

- **Gender**

```{r gender}
# Extract genger from dat
gender.name = "Gender"
gen.tab = dat[, .N, by = gender.name]

# Adding a column, called Percentage, to the table
gen.tab[, Percentage := gen.tab[, lapply(.SD, FUN = 'percentage.mark'), .SDcols = "N"]]

datatable(gen.tab)

# Uniq gender
gender.uniq.tab = dat[, length((unique(get(id.name)))), keyby = gender.name]
setnames(x = gender.uniq.tab, old = "V1", new = "Numbers")
gender.uniq.tab[, Percentage := gender.uniq.tab[, lapply(.SD, FUN = 'percentage.mark2'), .SDcols = "Numbers"]]

datatable(gender.uniq.tab)

```


- **Income Group**

```{r income_group}
income.name = "Income"
income.group.name = "Income Group"
cuts.income <- 1000* c(0, 50, 75, 100, 150, 250)
# Demarcating Income groups
dat[, eval(income.group.name) := cut2(x = get(income.name), cuts = cuts.income)]

# Extracting income group from dat
income.tab = dat[, .N, keyby = income.group.name]

# Adding a column, called Percentage, to the table
income.tab[, Percentage := income.tab[, lapply(.SD, FUN = 'percentage.mark'), .SDcols = "N"]]

datatable(income.tab)

# Uniq Incom
income.uniq.tab = dat[, length((unique(get(id.name)))), keyby = income.group.name]
setnames(x = income.uniq.tab, old = "V1", new = "Numbers")
income.uniq.tab[, Percentage := income.uniq.tab[, lapply(.SD, FUN = 'percentage.mark2'), .SDcols = "Numbers"]]

datatable(income.uniq.tab)
```

- **Region**: 

```{r region}
# Extracting regrion from dat
region.name = "Region"
region.tab = dat[, .N, keyby = region.name]

# Adding a column, called Percentage, to the table
region.tab[, Percentage := region.tab[, lapply(.SD, FUN = 'percentage.mark'), .SDcols = "N"]]

datatable(region.tab)

# Uniq Region
region.uniq.tab = dat[, length((unique(get(id.name)))), keyby = region.name]
setnames(x = region.uniq.tab, old = "V1", new = "Numbers")
region.uniq.tab[, Percentage := region.uniq.tab[, lapply(.SD, FUN = 'percentage.mark2'), .SDcols = "Numbers"]]

datatable(region.uniq.tab)
```
 
- **Persona**

```{r persona}
# Demarcating persona from dat
persona.name = "Persona"
persona.tab = dat[, .N, keyby = persona.name]

# Adding a column, called Percentage, to the table
persona.tab[, Percentage := persona.tab[, lapply(.SD, FUN = 'percentage.mark'), .SDcols = "N"]]

datatable(persona.tab)

# Uniq Persona
persona.uniq.tab = dat[, length((unique(get(id.name)))), keyby = persona.name]
setnames(x = persona.uniq.tab, old = "V1", new = "Numbers")
persona.uniq.tab[, Percentage := persona.uniq.tab[, lapply(.SD, FUN = 'percentage.mark2'), .SDcols = "Numbers"]]

datatable(persona.uniq.tab)

```

**b.** Now create a visual display of this information.  Allow the user to select which variable to explore.  Then create a graph that depicts the percentages of respondents in each category for that variable.

```{r engine_q1, echo=FALSE}

```
Please see the reporting engine for this solution.

```{r question2, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Segmented Outcomes

**a.** What are the top 5 products by Awareness rates in the Northeast?  Round the percentages to 1 decimal place, e.g. 84.2%.

```{r awareness_northeast_top5}
product.name <- "Product"
awareness.name <- "Awareness"

# Check for errornous value for Awareness
uniq.aware <- dat[,unique(get(awareness.name))] # 0,1

# Creating awareness table by products 
awareness.NE.top = dat[get(region.name) == "Northeast" & get(awareness.name) == 1, length(unique(get(id.name))), by = product.name]

setnames(x = awareness.NE.top, old = "V1", new = "Num_Aware")

awareness.NE.top[,`Aware rate` := 100 * awareness.NE.top[,2] / dat[get(region.name)== "Northeast",length(unique(get(id.name)))]]

setorderv(x = awareness.NE.top, cols = 'Aware rate', order = -1)

awareness.NE.top[, `Aware rate` := sprintf("%.1f %%", `Aware rate`)]

datatable(awareness.NE.top[1:5])
```


**b.** What are the top 5 products by Advocacy rates among females who earn at least $100,000?    Round the percentages to 1 decimal place, e.g. 84.2%.

```{r advocacy_females_100kplus_top5}
advocacy.name <- "Advocacy"

# Check for errornous value for Awareness
uniq.advocacy <- dat[,unique(get(advocacy.name))] # NA, 0,1
dat[is.na(get(advocacy.name)), .N] # 183516

# See if 183516 of NA is reasonable by implementing upsteam and downstreaming
dat[, .N, keyby = c(awareness.name, consideration.name)] # Checks out
dat[, .N, keyby = c(consideration.name, consumption.name)] # Checks out
dat[, .N, keyby = c(consumption.name,advocacy.name)] # Checks out
# Final Check
dat[, .N, keyby = c(awareness.name, consideration.name, consumption.name, advocacy.name)] # the NA matches with the number of NA of advocacy! 

# Extracting female and least 100K out of data
advocacy.females.100k = dat[get(gender.name) == 'Female' &  get(income.name) >= 100000 & get(advocacy.name) == 1, .(Num_Advocates = length(unique(get(id.name)))), by = product.name]


# Calcuating the rates
advocacy.rate.females.100k = dat[get(gender.name) == 'Female' & get(income.name) >= 100000, .(`Advocacy rate` = 100* mean(get(advocacy.name), na.rm = TRUE)), by = product.name]

# putting the tabs together
advocacy.females.100k.top = merge(x = advocacy.females.100k, y = advocacy.rate.females.100k, by = 'Product')

setorderv(x = advocacy.females.100k.top, cols = 'Advocacy rate', order = -1)

advocacy.females.100k.top[, `Advocacy rate` := sprintf("%.1f %%", `Advocacy rate`)]


datatable(advocacy.females.100k.top[1:5])
```


**c.** Now create a dynamic, visual display ranking the products by their outcomes.  The user will make the following selections:

State of engagement:  Only a single state may be selected at once.

Other variables:  Age Group, Gender, Income Group, Region, Persona

Then, for all of the other variables, any combination of categories may be selected, so long as at least one category from each variable is chosen.  For instance, for Gender, the user may select Male only, Female only, or both Male and Female.

Then, the user should be able to select how many products to display.  Once a number is selected, the outcome rates should be graphically displayed in sorted decreasing order for the top products in the selected subgroups.  If 5 is selected for Awareness, then the 5 products with the highest rates of Awareness for the specified subgroup will be depicted.  Make sure to include the percentages in the graph, each rounded to 1 decimal place (e.g. 84.2%).

```{r engine_q2, echo=FALSE}

```
Please see the reporting engine for this solution.

```{r question3, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Overall Brand Perceptions

**a.** What are the top 5 brands by the overall average perception?

Evaluating this question can be tricky.  Some of the perceptions are for positive traits, and others are for negative traits.  The brand with the best overall perception would have the highest scores for the positive traits and the lowest scores for the negative traits.  To aggregate these scores, we will follow a number of steps:

1.  For each brand, compute the average score of each brand perception variable.  In computing these averages, remove any missing values from the calculations.

2.  Then, for the negative perceptions, invert the scores to place them on a comparable scale with the positive traits.  To do this, use the conversion formula:

Inverted Score = min possible score + max possible score - recorded score = 10 - recorded score.

The minimum and maximum possible scores here are 0 and 10.  Therefore, the inverted average score is:

Inverted Average Score = 10 - Average Score.

3.  With all of the average scores of each perception now recorded on the same scale, we can aggregate them into one measure, the Overall Average Perception.  For each brand, compute the mean of these variable averages.  (To be clear:  within a single product, you can add up the average scores for each perception and then divide by the number of perceptions.)

4.  Now rank the brands in decreasing order of their Overall Average Perception scores.

5.  Show the results for the top 5 brands.

```{r overall_average_perception}
# 1. look for errorneous perceptions. 
sum(dat[, 9:20] < 0 | dat[, 9:20] > 10, na.rm = T)

# 2. Computing the avg score for each brand perception variable.
bp.variables = grep(pattern = "BP_", x = names(dat))
bp.tab = dat[, lapply(.SD, FUN = "mean", na.rm = T), .SDcols = names(dat)[bp.variables], by = product.name]

# 3. Inverting scores
negative.perception <- names(dat)[17:20]

invert.score <- function(x){
  max = 10
  return(max-x)
}

bp.neg.tab = bp.tab[, lapply(.SD, FUN = "invert.score"), .SDcols = negative.perception]

# 4. Combining the bp.neg.tab and bp.tab
bp.avg.tab = cbind(bp.tab[, 1:9], bp.neg.tab)

# 5. Overall Avg perceoption
bp.overall.tab = bp.avg.tab[, .(Product = get(product.name),
                                `Overall avg` = rowMeans(bp.avg.tab[,2:13], na.rm = T))] 

# Sort by Overall avg and round it up
setorderv(x = bp.overall.tab, cols = 'Overall avg', order = -1)
bp.overall.tab[, `Overall avg` := round.numerics(`Overall avg`, digits = 1)]

# 6. showing the Top5
datatable(data = bp.overall.tab[1:5], rownames = F)
```

**b.** Now create a dynamic, graphical display that allows the user to perform this calculation in selected subgroups.  Much like the previous question, the user may make any combination of selections in the following variables, provided that at least one category of each variable is selected:  Age Group, Gender, Income Group, Region, Persona.

Also allow the user to select how many brands should be displayed, with the top k brands depicted in decreasing sorted order.  All results should display the overall average perception for the brand, rounded to 1 decimal place (e.g. 6.1).  

```{r engine_q3, echo=FALSE}

```
Please see the reporting engine for this solution.


```{r question4, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`: Outcomes Gaps

The marketing department wants to identify products with engagement that is underperforming in some ways.  The best products should have high rates of engagement across all of the outomes, but that is not always the case.

For the purposes of this question, we will work with the average rate of each state of engagement.  To ensure a fair comparison, we will place all of the outcomes on a percentage scale from 0 to 100.  For binary outcomes (awareness, consideration, consumption, and advocacy), the average will be the percentage of the respondents who answered yes to the question among those who were asked.  For outcomes on an integer scale (e.g. Satisfaction), the average will be percentage of the maximum score.  So, for instance, if the average satisfaction for a product is 7, then its percentage rating would be 70%.

**a.**  Which 5 products have the largest gap between the rate of consumption and the rate of awareness?  This would correspond to a formula of Difference = Rate of Consumption - Rate of Awareness.  Products with higher rates of awareness than the corresponding rates of consumption will have negative differences.  Display a bar graph showing the 5 largest differences in decreasing sorted order.  Include the differences as percentages rounded to 1 decimal place (e.g. 84.2%).


```{r comsumption_awareness_gaps_top5}
# Check for the errorneous NA
dat[, .N, keyby = c(awareness.name, consideration.name, consumption.name)] # No such thing as wierd number

# Extracting awareness and consumption rate form dat
awareness.consumption.tab = dat[, .(Awareness = 100 * mean(get(awareness.name), na.rm = T), Consumption = 100 * mean(get(consumption.name), na.rm = T)), by = product.name]

# Expending a col, Difference. 
awareness.consumption.diff.tab = awareness.consumption.tab[, Difference := Consumption - Awareness]
# sort by Difference
setorderv(awareness.consumption.diff.tab, cols = "Difference", order = -1)
# Cut out Top5
awareness.consumption.diff.tab.Top5 = awareness.consumption.diff.tab[1:5, ]

library(ggplot2)
library(scales)
# Plotting bar plot (geom_bar)
ggplot(data = awareness.consumption.diff.tab.Top5, aes(x = reorder(Product, -Difference), y = Difference, fill = Product)) +
  geom_bar(stat = "identity", colour="black") +
  scale_fill_brewer(palette = "Spectral") +
  geom_text(aes(label = sprintf("%.1f %%", Difference)), vjust = -0.5, size = 4) +
  theme(legend.position = "none") +
  xlab("Name of Products") +
  ylab("Difference Rate") +
  ggtitle("Top 5 products by difference rate")
```

**b.**  Which 5 products have the largest gap between the rate of awareness and the average satisfaction (in percentage terms)?  Here the formula would be Difference = Rate of Awareness - Percentage Average Satisfaction.  Display a bar graph showing the 5 largest differences in decreasing sorted order.  Include the differences as percentages rounded to 1 decimal place (e.g. 84.2%).  

```{r awareness_satisfaction_gaps_top5}
# Check for the errorneous NA
dat[, .N, keyby = c(awareness.name, consideration.name, consumption.name, satisfaction.name)] # No such thing as wierd number

# Extracting awareness and consumption rate form dat
awareness.satisfaction.tab = dat[, .(Awareness = 100 * mean(get(awareness.name), na.rm = T), Satisfaction = 10 * mean(get(satisfaction.name), na.rm = T)), by = product.name]

# Expending a col, Difference. 
awareness.satisfaction.diff.tab = awareness.satisfaction.tab[, Difference := Awareness - Satisfaction]
# sort by Difference
setorderv(awareness.satisfaction.diff.tab, cols = "Difference", order = -1)
# Cut out Top5
awareness.satisfaction.diff.tab.Top5 = awareness.satisfaction.diff.tab[1:5, ]

# Plotting bar plot (geom_bar)
ggplot(data = awareness.satisfaction.diff.tab.Top5, aes(x = reorder(Product, -Difference), y = Difference, fill = Product)) +
  geom_bar(stat = "identity", colour="black") +
  scale_fill_brewer(palette = "Accent") +
  geom_text(aes(label = sprintf("%.1f %%", Difference)), vjust = -0.5, size = 4) +
  theme(legend.position = "none") +
  xlab("Name of Products") +
  ylab("Difference Rate") +
  ggtitle("Top 5 products by difference rate")
```

**c.** Now create a dynamic, graphical display that ranks the products in terms of the difference in averages between any two selected outcomes.  The user will be allowed to make the following selections:

**First Outcome**:  One of the outcome variables.

**Second Outcome**:  Another outcome variable.  In practice, it would be nice to exclude the outcome that was selected first.  In practice, that requires some additional programming tools.  So it's OK to select the same variable twice.  In that case, all of the products should necessarily show a difference of zero.

The difference in rates will be Difference = Average First Outcome - Average Second Outcome per product.

**Number of Top Products**:  The user will select how many products to display.

**Display Percentages**:  If checked, the bargraph will display the percentages for each product.

**Digits**:  How many digits should the percentages be rounded to?  1 digit would be a number like 84.2%.

```{r engine_q4, echo=FALSE}

```
Please see the reporting engine for this solution.

```{r question5, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`: Cross-Product Measures

How much does a respondent's engagement depend on the product, and how much depends on the respondent?  One way we might investigate this further is to see whether the respondent's outcomes in other products has an impact on this one.  We will investigate this by the following steps:

**a.**  How much impact does respondent's overall trends in awareness have for that person's awareness with Buzzdial phones?  To answer this question, we want to create a logistic regression model.  The outcome will be the respondents' Awareness of Buzzdial.  The variables in the model will include age group, gender, income group, region, persona, and the **aggregated awareness**.  The aggregated awareness will be the average of the respondent's awareness scores for all of the products *except for Buzzdial*.  Each respondent will have a different value of aggregated awareness. Any missing scores should be removed from the calculation of the aggregated awareness.  Then, fit the logistic regression model.  Display a table including the model's Odds Ratios, 95% confidence intervals for the Odds Ratios, and the p-values.  In particular, show these values for the aggregated awareness variable and comment on the results.  Round all of the results to 3 decimal places.

```{r aggregated_awareness_buzzdial_model}
# creating a tab for aggregated_awareness all except for Buzzdial
aggregated.awareness.name = "Aggergated.Awareness"
aggregated.aware.tab = dat[get(product.name) != "Buzzdial", .(Aggergated.Awareness = mean(get(awareness.name), na.rm = T)), by = id.name]


# Pulling out the buzz.awareness from dat
respondent.outcome = c(id.name, product.name, awareness.name, age.group.name, gender.name, income.group.name, region.name, persona.name)

Buzz.awareness.tab = dat[get(product.name) == 'Buzzdial', .SD, .SDcols = names(dat) %in% respondent.outcome]

# Merging the two tabs and removing id column
model.tab = merge(aggregated.aware.tab, Buzz.awareness.tab, by = id.name)

# Building a logistic regression model 
model1 = glm(formula = Awareness ~ `Age Group` + `Income Group` + Gender + Region + Persona + Aggergated.Awareness, data = model.tab, family = 'binomial')

# Building the reporting table 
alpha = 0.05
z <- qnorm(p = 1-alpha/2, mean = 0, sd = 1)

report.tab = as.data.table(summary(model1)$coefficients, keep.rownames = T)
report.tab[, `Odds Ratio` := exp(Estimate)]
report.tab[, OR.Upper.95 := exp(Estimate + z * `Std. Error`)]
report.tab[, OR.Lower.95 := exp(Estimate - z * `Std. Error`)]

# Extacting Aggregated Awareness
aggregated.aware.report = report.tab[rn == eval(aggregated.awareness.name),c(1,5:8)]

# Rounding digits and show
datatable(aggregated.aware.report[, lapply(X = .SD, FUN = 'round.numerics', digits = 3)])

```
**Comments:**
The Odd ratio of this regression, 0.765, is less than 1, which implies that peopleâ€™s overall awareness has nearly 24% less likely aware of the product, Buzzdial. Yet, judging from the Confidence Interval, which includes 1 in between Upper 95% and Lower 95%, I could not simply make an assertion that it has a negative impact on the awareness of Buzzdial. In addition to that, P-value, 0.226, is not statistically significant, which also buttress the point that we cannot reject the null hypothesis: there is no relationship between overall awareness and the that of Buzzdial. In short, I would say that the aggregated awareness has no impact on that of Buzzdial.   (Odd of people aware of Buzzdial in the sample data are 24% less likely aware of the other products with the true population effect between 118.1 % and 49.5%. This result is not statistically significant) 



**b.** How much impact does respondent's overall trends in satisfaction have for that person's satisfaction with Buzzdial phones?  To answer this question, we want to create a linear regression model.  The outcome will be the respondents' Satisfaction with Buzzdial.  The variables in the model will include age group, gender, income group, region, persona, and the **aggregated satisfaction**.  The aggregated satisfaction will be the average of the respondent's satisfaction scores for all of the products *except for Buzzdial*.  Each respondent will have a different value of aggregated satisfaction.  Any missing scores should be removed from consideration.  Then, fit the linear regression model.  Display a table including the model's coefficients, 95% confidence intervals for the coefficients, and the p-values.  In particular, show these values for the aggregated satisfaction variable and comment on the results.  Round all of the results to 3 decimal places.

```{r aggregated_satisfaction_buzzdial_model}
# creating a tab for aggregated satisfaction all except for Buzzdial
aggregated.statisfaction.name = "Aggregated.Satiscation"
aggregated.staisfaction.tab <- dat[get(product.name) != "Buzzdial",.(Aggregated.Satiscation = mean(get(satisfaction.name),na.rm = TRUE)),by = id]

# Pulling out the buzz.satisfaction from dat
respondent.outcome = c(id.name, product.name, age.group.name, satisfaction.name, gender.name, income.group.name, region.name, persona.name)

Buzz.satisfaction.tab <- dat[get(product.name) == "Buzzdial",.SD,.SDcols = names(dat) %in% respondent.outcome]

# Merging the two tabs and removing id column
model2.tab = merge(aggregated.staisfaction.tab, Buzz.satisfaction.tab, by = id.name)

# Building a logistic regression model 
model2 = lm(formula = Satisfaction ~ `Age Group` + `Income Group` + Gender + Region + Persona + Aggregated.Satiscation, data = model2.tab)

# Building the reporting table 
alpha = 0.05
z <- qnorm(p = 1-alpha/2, mean = 0, sd = 1)

report.tab2 = as.data.table(summary(model2)$coefficients, keep.rownames = T)
report.tab2[, OR.Upper.95 := Estimate + z * `Std. Error`]
report.tab2[, OR.Lower.95 := Estimate - z * `Std. Error`]

# Extacting Aggregated Awareness
aggregated.satisfaction.report = report.tab2[rn == "Aggregated.Satiscation",c(1:2,5:7)]

# Rounding digits and show
datatable(aggregated.satisfaction.report[, lapply(X = .SD, FUN = 'round.numerics', digits = 3)])

```
**Comments:** 
The result of the estimated value of aggregated satisfaction is 0.105. And, the P-value of that is significant, which means that we can reject the null hypothesis: there is no relationship between the two groups, aggregated satisfaction and the satisfaction of the product, Buzzdial. In other words, even though the estimated value of overall satisfaction is low, it still has a positive impact on the satisfaction of the Buzzdial. 


**c.** Now we will create a dynamic model that allows the user to build a model including an aggregated outcome for a specific product.  The site should include the following features:

* The user can select the product.

* The user can select the state of engagement as the outcome.

* The user can select the other variables to include in the model.  The list of choices should include the age group, gender, income group, region, persona, brand perceptions, and the Aggregated Engagement.  Each person's aggregated engagement will be calculated as the average score of the selected state of engagement across the measured values of the other products .  You can give this variable a name like "Aggregated.Engagement".

The user's selections will then be incorporated into a model.  For Satisfaction outcomes, use a linear regression.  For all of the other outcomes, use a logistic regression.  Then create a dynamic table showing the model's results.  For logistic regressions, this must include the Odds Ratios, 95% confidence intervals for the Odds ratios, and the p-values.  For linear regressions, this must include the coeffiients, 95% confidence intervals for the coefficients, and the p-values.  Other factors may be included but are not necessary.  Round all of the results to 3 decimal places.

```{r engine_q5, echo=FALSE}

```

Please see the reporting engine for this solution.