---
title: "Homework 4"
author: "Caffrey Lee (cl3802, cl3802@columbia.edu)"
date: "2019-05-02"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, eval = TRUE, comment="", warning = FALSE, message = FALSE, tidy.opts=list(width.cutoff=55), tidy = TRUE)
```


```{r libraries, echo=FALSE}
library(prettydoc)
library(data.table)
library(Hmisc)
library(scales)
library(DT)
library(lubridate)
```

```{r constants, echo=FALSE}
id.name <- "id"
connection.id.name <- "connection_id"
registration.time.name <- "registration.time"
num.common.connections <- "# of common connections"

selected.user <- 2000
min.common.connections <- 30

min.connections.q3 <- 250
min.photos.q3 <- 200
min.connection.connections.q3 <- 150

x.per.day <- 5
first.x.days <- 7

x.more <- 100

```

```{r my_functions, echo=FALSE}
round.numerics <- function(x, digits = 0, nearest = 1){
  if(is.numeric(x)){
    return(nearest * round(x = x/nearest, digits = digits))
  }
  else{
    return(x)
  }
}

repair.broken.microseconds <- function(x){
   require(data.table)

   the.pieces <- as.data.table(t(as.data.table(strsplit(x = x, split = ":"))))

   setnames(x = the.pieces, old = names(the.pieces), new = c("date_hours", "minutes", "seconds", "microseconds"))

   the.pieces[microseconds == "00Z", microseconds := "000000Z"]

   the.times <- the.pieces[, sprintf("%s:%s:%s%s", date_hours, minutes, seconds, microseconds)]

   return(the.times)
}
```

```{r read_data_intro, echo=FALSE, eval=TRUE, results='hide'}
toc <- Sys.time()
profiles <- fread(input = "~/Applied Data Science/hw4/data/Profiles.csv")
connections <- fread(input = "~/Applied Data Science/hw4/data/Connections.csv")
registrations <- fread(input = "~/Applied Data Science/hw4/data/Registrations.csv", colClasses = c("character", "POSIXct"), showProgress = FALSE)


registrations[, original.registration.time := get(registration.time.name)]
registrations[, eval(registration.time.name) := ymd_hms(get(registration.time.name))]

w <- which(registrations[, is.na(get(registration.time.name))])

registrations[w, eval(registration.time.name) := ymd_hms(repair.broken.microseconds(x = original.registration.time))]

registrations[,first.registration.time := min(get(registration.time.name)),by = id.name]
tic <- Sys.time()

num.lines <- 20
question.counter = 0
```


## About The Data

We will be working with a simulated data set related to social media sites.  The data are stored in several files:

**Profiles.csv**:  Information about the users with some fields from their profiles.

**Connections.csv**:  Information about which users are connected to other users.

**Registrations.csv**: Information about history of the user's account registrations (logins) over time.

**Header** The first row of the data set includes the column names, and each subsequent row includes one observation of values.  Here is a selection of `r num.lines` lines from each data file:

```{r show_header, echo=FALSE, comment=""}
datatable(data = profiles[1:num.lines,])
datatable(data = connections[1:num.lines,])
datatable(data = registrations[1:num.lines,])
```


Here is a brief description of each variable across the three files:

**Profiles Variables**:

- **id**:  A unique identifying string for each user.

- **density**:  The type of area the user lives in, with categories of Urban, Suburban, and Rural areas.

- **gender**:  female (F) or male (M).

- **has_profile_photo**:  1 if yes, 0 if no.

- **num_photos**:  This is the number of photos the user has uploaded to the site.

- **date_created**:  This is the date that the user first joined the site.

**Connections Variables**:

- **id**:  A unique identifying string for each user.

- **connection_id**:  This is the identifier of another user that the user listed under **id** is connected to.

This site chooses to use one-way connections.  A user can connect to a second user's profile without requiring that the second user reciprocally connect to the first one.  So, for any row in the Connections data, the user labeled with **id** is following the user labeled with **connection_id**.  In some cases, pairs of users are mutually following each other, but this is by no means required.  For mutual connections, the users will be coupled in two different rows in the two possible orders.  Each connection for a single user is recorded in a separate row.

**Registrations Variables**:

- **id**:  A unique identifying string for each user.

- **registration.time**:  This is the date and time that a user registered by logging in to the site.  Each registration for a user is recorded in a separate row.


```{r question1, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Classifying Connections

How often do users mutually follow each other, and how often are the connections one-way?  We want to investigate this.  For the investigation, we'll say that a two-way connection requires two one-way connections (two rows of data) but only counts once.  Therefore, the number of overall connections (total one-way plus total two-way) will be less than the overall number of rows of data in the Connections file.  With this in mind, answer these questions.

What percentage of all connections are one-way connections, and what percentage of all connections are two-way connections?

```{r connection_directionality_percentages}
# Checking unique ID for both id and connection_id
connections[, length(unique(get(id.name)))] # 10000
connections[, length(unique(get(connection.id.name)))] # 10000

all.connections = nrow(connections)

# if a -> b and if b -> a then its two way. only one of them did then one way!!

# tracking the connections
tab1 = connections[, .(first = paste(get(id.name), get(connection.id.name), sep = " "))]
tab2 = connections[, .(second = paste(get(connection.id.name), get(id.name), sep = " "))]

tab = cbind(tab1, tab2)

# two-way connections: check if a<->b /2 
two_way_connection = tab[first%in%second, .N]/2

# one-way connections : 
one_way_connection = all.connections - two_way_connection*2

# total connections : 
total_connection = two_way_connection + one_way_connection

# creating result table :
result = data.table(one_way_connection_perc = one_way_connection / total_connection * 100,
                    two_way_connection_perc = two_way_connection / total_connection * 100)

datatable(data = result[, lapply(.SD, FUN = function(x){sprintf("%.3f %%", x)})], rownames = F)
```



```{r question2, echo=FALSE}
question.counter <- question.counter + 1
```

```{r the_id, echo = FALSE}
the.id <- profiles[selected.user, id]
```


## Question `r question.counter`: Recommending Connections

Which connections should we recommend to the user with id `r the.id`?  One way is to find the unconnected users who are connected to users that user `r the.id` is also connected to.  Create a table of all the users who satisfy all of the following criteria: 
  
* have at least `r min.common.connections` connections in common with user `r the.id`'s connections, and
* are not already connected with user `r the.id`.  
  
The list should show the ids of the recommended users and the number of common connections they have with user `r the.id`.  Order the list in decreasing order of mutual connections.  Make sure not to include `r the.id` on the list of recommendations!


```{r recommendations}
# the.id
# min.common.connections # 30

# condition: find users not connected to the.id but have common connections; common connections should have least 30; and exclude the.id

# get the the.id connections list
the.id.connections = connections[get(id.name) == the.id, get(connection.id.name)]

# creating recommendtation list tab
recommendation.list.tab = connections[!get(id.name) %in% c(the.id, the.id.connections) & get(connection.id.name) %in% the.id.connections, .(num_connections = length(unique(get(connection.id.name)))), by = id.name]

# taking the ones only meet the condition
selected.list.tab = recommendation.list.tab[num_connections >= min.common.connections, ]

datatable(data = setorderv(selected.list.tab, cols = 'num_connections', order = -1))
```


```{r question3, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Influential Connections

In social networks, some users are considered **influential**.  They tend to have more connections, and their content can be widely viewed and shared.  For our purposes, we will define the **influential users** as those who:

* Have at least `r min.photos.q3` photos, and 
* Have at least `r min.connection.connections.q3` connections.

Among all users (both influential and not so influential), how many users are connected to at least `r min.connections.q3` **influential** users?


```{r characteristics_of_connections}
# conditions: have least 200 photos and 150 connections
# creating new tab count num of connections
min.connection = 150
num_connections = connections[, .(num_connections = length(unique(get(id.name)))), by = connection.id.name]

num_150_connections = num_connections[num_connections >= min.connection, ]

# creating new tab count num of photos
num.photo.name = "num_photos"
min.photo = 200
num_photos = profiles[, .(num_photos = unique(get(num.photo.name))), by = id.name]
num_200_photos = num_photos[num_photos >= min.photo, ]

influencer = merge(num_200_photos, num_150_connections, all.x = F, all.y = F, by.x = "id", by.y = "connection_id")

# check the num of influencers
num.influencer = influencer[, .N] # there are 4461 influencers in total

# geting influencer list
influencer.list = influencer[, unique(get(id.name))]

# check the users with connections with at least 250 influencers
influencer.tab = connections[get(connection.id.name) %in% influencer.list, .(num_connections = .N), by = id.name ]

# selecting the ones with least 250 connections with influencers
min.influecers = 250
influencer.result = influencer.tab[num_connections >= min.influecers, .N]

print(influencer.result)
```




```{r question4, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`: Early Utilizers

Starting from the time when the account for each user was created, what percentage of all users logged in at least `r x.per.day * first.x.days` times during the first `r first.x.days`?  Round your answer to 1 decimal point, e.g. 84.2%.

**Hints**:  Within the **lubridate** library, you can use the function **days** to add a specified number of days to the registration times.  The first week ends before (less than) the user's first registration time plus 7 days.  The registration that occurred when the account was created counts toward the overall total for this period.


```{r regular_users}
library(lubridate)
library(formatR)
#x.per.day #5
#first.x.days #7

# str(profiles)
# str(registrations)

registration.name = "registration.time"

# condition : logged in at least 35 times in the first 7 days 
profiles_registrations = merge(profiles, registrations, by = "id")

# creating new tab for the first 7 days only 
utilizer.tab = profiles_registrations[registration.time >= first.registration.time & registration.time < first.registration.time + days(x = first.x.days), .N, by = id]

# selecting the ones meets criteria
utilizer.count = utilizer.tab[N >= (x.per.day * first.x.days), .N] # 2970

# calculating the total number of users
total.user.number <- registrations[,length(unique(get(id.name)))]

# calculating the utilizer perc.
utilizer.result =  100 * utilizer.count / total.user.number
sprintf("%.1f %%", utilizer.result)

```



```{r question5, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`: Imbalanced Connections

What percentage of users have at least `r x.more` more followers than the number of users that they are following?  Round the answer to 1 decimal place, e.g. 84.2%.

```{r imbalanced_connection_percentage}
# x.more # 100

# following tab 
following.tab = connections[, .(following = length(unique(get(connection.id.name)))), by = id.name]

# follower tab
follower.tab = connections[, .(follower = length(unique(get(id.name)))), by = connection.id.name]

# merge them together
follow.tab = merge(following.tab, follower.tab, by.x = eval(id.name), by.y = eval(connection.id.name))

# new col computing the difference 
follow.tab[, difference := follower - following, by = id.name]

# selecting the ones meet the condition follower >= following +100
imbalanced.numb = follow.tab[difference >= x.more, .N]

imbalanced.result = imbalanced.numb / total.user.number *100
sprintf("%.1f %%", imbalanced.result)
```





```{r question6, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Active Users

What percentage of unique users in the sample were active (with at least 1 registration) between 00:00:00 of January 1st, 2017 and 23:59:59 on January 7th, 2017?  Round the percentage to 1 decimal place, e.g. 84.2%

**Hint**:  For any given date in character format (e.g. "1999-07-01"), you can calculate a date in the future with the **as.Date** function:  as.Date("1999-07-01") + 3 would result in "1999-07-04".

```{r active_users}

# counting the number of active users between 00:00:00 of January 1st, 2017 and 23:59:59 on January 7th, 2017
first.date = as.Date("2017-01-01")
second.date = first.date + days(x = first.x.days) 

active_user.num = registrations[get(registration.name) >= first.date & get(registration.name) < second.date, length(unique(get(id.name)))]

active_user.result = active_user.num / total.user.number *100
sprintf("%.1f %%", active_user.result)
```


```{r question7, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Burning the Midnight Oil

Across all days, what percentage of all registrations occur between the hours of 00:00:00 and 05:59:59, inclusive of both endpoints?  Round your answer to 1 decimal place, e.g. 84.2%.  **Hint:**  Use the hour() function to classify the time of day.


```{r midnight_oil}

# checking the hour function 
# head(hour(registrations$registration.time)) # 24 hr scale,i.e. its btw 0 and 6

first.hour = 0
second.hour = 6

# calculating the midnight_oil
midnight_oil.num = registrations[hour(get(registration.name)) >= first.hour & hour(get(registration.name)) < second.hour, .N]

total.registration = nrow(registrations)
midnight_oil.result = midnight_oil.num / total.registration *100
sprintf("%.1f %%", midnight_oil.result)
```



```{r question8, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Retention Rates

What percentage of users were retained at 183 days (half a year)?  To answer this question, we will use a 7 day window.  Any user who had at least one registration in the period of time that was at least 183 days and less than 190 days from their first registration would be considered retained.  Round your answer to 1 decimal place, e.g. 84.2%.

**Note:** The evaluation window would begin at exactly 183 days after the first registration.  This period lasts for 7 days.  This window would include the left end-point but not the right end-point.  The registration times are listed in the data set rounded to the nearest second. If the user had at least 1 registration during this window, the user would be considered retained at 183 days (approximately 6 months).

**Hint:**  You may use the **days()** function to add time to a user's initial registration time.


```{r retention_rate}

half.year = 183
first.day = "first_day"
last.day = "last_day"
# get the users initial regisration time and add lastday
first.registration = registrations[, .SD[1,], by = id.name]
first.registration[, last_day := get(registration.name) + days(x = half.year)]
setnames(first.registration, old = eval(registration.name), new = eval(first.day))

registration.with.firstday = merge(first.registration, registrations, all.x = T, by = 'id')

# select the users meets the condition who had at least one registration in the period of time that was at least 183 days and less than 190 days from their first registration
retention.num = registration.with.firstday[get(registration.name) >= get(last.day) &get(registration.name) < (get(last.day) + days(x = first.x.days)), length(unique(get(id.name)))]

retention.result = 100*retention.num / total.user.number
sprintf("%.1f %%", retention.result)
```

```{r question9, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  False Positive Rates

In the previous question, we estimated the rate of retention at 6 months using a 7-day window for evaluation.  What is the rate of false positives for the 7-day window?  In other words, what percentage of users who were considered not retained at 6 months using a 7-day window later had a registration?  Round the results to 2 decimal places, e.g. 84.23%.

```{r false_positive_rate}
retention.users = registration.with.firstday[get(registration.name) >= get(last.day) & get(registration.name) < (get(last.day) + days(x = first.x.days)), unique(get(id.name))]

false_positive.num = registration.with.firstday[!get(id.name) %in% retention.users & get(registration.name) >= get(last.day) + days(x = first.x.days), length(unique(get(id.name)))]

false_positive.result = false_positive.num / (total.user.number - retention.num) *100

sprintf("%.2f %%", false_positive.result)
```



```{r question10, echo=FALSE}
question.counter <- question.counter + 1
```

## Question `r question.counter`:  Modeling Retention

Build a logistic regression model for retention at 6 months.  Classify users as retained at 6 months if they have any account registrations at times at least 183 days after their account was created.  Include the following variables:
  
* density
* age_group
* gender
* num_photos (categories:  0-24, 25-49, 50-99, 100-249, 250-499, 500+)  (current status)
* average daily registrations in the first week.  (To simplify matters, let this be the total number of registrations in the first week divided by 7, regardless of whether the user's retention truly lasted 7 days or not.)
* number of connections the user currently has
* number of users currently connected to this user

Display the odds ratios, confidence intervals for the odds ratios, and p-values for the coefficients, rounded to 3 digits.  Then briefly comment on the results.

```{r retention_model}
library(Hmisc)
num.photos.group <- "num_photos_gourp"
# check the status of num_photos
# str(profiles$num_photos) # its not in categorical, need to make new one 

## data preperation
# cutting them into grp
photo.group = c(25, 50, 100, 250, 500)
profiles[, eval(num.photos.group) := cut2(x = get(num.photo.name), cuts = photo.group)]

# average daily registrations in the first week
avg.daily.registration = profiles_registrations[registration.time >= first.registration.time & registration.time < first.registration.time + days(x = first.x.days), .(avg.daily.regisration = length(get(registration.name)) / first.x.days), by = id.name]

# follower and following numbs are under follow.tab
follow.select = follow.tab[,1:3]

# retention.6month.users under retention.users and adding new col, retention, to profile
retention.users.new <- profiles_registrations[registration.time >= first.registration.time+days(x = half.year), unique(get(id.name))]
profiles[, retention := get(id.name) %in% retention.users.new]


# density, age_group, gender, photo.group, avg.daily(first.wk), num of follower and following combined tab
avg.daily.registration_profiles.select = merge(avg.daily.registration, profiles, all.x = F, all.y = F, by = "id")
avg.daily.registration_profiles.select_follow.select = merge(avg.daily.registration_profiles.select, follow.select, all.x = F, all.y = F, by = "id")

############################################################################

# modeling 
formula <- retention ~ density+age_group+gender+num_photos_gourp+following+follower+avg.daily.regisration
glm.model = glm(formula = as.formula(formula), data = avg.daily.registration_profiles.select_follow.select, family = 'binomial')

glm.coefs <- as.data.table(summary(glm.model)$coefficients, keep.rownames = TRUE)
alpha = 0.05
z <- qnorm(p = 1-alpha/2, mean = 0, sd = 1)
glm.coefs[, Odds.Ratio := exp(Estimate)]
glm.coefs[, OR.Lower.95 := exp(Estimate - z * `Std. Error`)]
glm.coefs[, OR.Upper.95 := exp(Estimate + z * `Std. Error`)]

datatable(glm.coefs[, lapply(X = .SD, FUN = "round.numerics", digits = 3)][,c(1,5:8)])

```

** Comments ** : 

Based on the P value, one could claim that the user retention rate is affected by density, age, all age groups but not the 25 – 34 group, gender, number of followings, and average daily registration, in this case avg.daily.registration. Most importantly, the average daily registration and number of following have the positive impact on the retention rate, of which Odd Ratio are 2.276 and 1.004, while that of other influential factors less than 1. In other words, people with higher average daily registration rate and higher number of followings are more likely to keep using the service. 

The result is reasonable: we often see that people who use a product or services more often tend to use it maintain using the product or service. Moreover, in terms of SNS, some people, including me, keep their accounts to merely see other people’s feeds, but do not post their things, including photos, words, and such. 

In short, the result is valid that people with higher number of followings and average daily registration rate tend to stay with the service. 
